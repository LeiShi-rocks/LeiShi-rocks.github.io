<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
<title>AI Papers</title>
<link>https://example.com/ai-trend-feed</link>
<description>Top daily AI papers</description>
<lastBuildDate>Thu, 12 Feb 2026 09:00:08 +0000</lastBuildDate>
<item>
<title>Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling</title>
<link>https://tldr.takara.ai/p/2602.11146</link>
<guid>title:beyond vlm based rewards diffusion native latent reward modeling</guid>
<pubDate>Wed, 11 Feb 2026 18:57:29 +0000</pubDate>
<description>Preference optimization for diffusion and flow-matching models relies on reward functions that are both discriminatively robust and computationally efficient. Vision-Language Models (VLMs) have emerged as the primary reward provider, leveraging their rich multimodal priors to guide alignment. However, their computation and memory cost can be substantial, and optimizing a latent diffusion generator through a pixel-space reward introduces a domain mismatch that complicates alignment. In this paper, we propose DiNa-LRM, a diffusion-native latent reward model that formulates preference learning directly on noisy diffusion states. Our method introduces a noise-calibrated Thurstone likelihood with diffusion-noise-dependent uncertainty. DiNa-LRM leverages a pretrained latent diffusion backbone with a timestep-conditioned reward head, and supports inference-time noise ensembling, providing a diffusion-native mechanism for test-time scaling and robust rewarding.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>alignment</category>
<category>daily</category>
<category>diffusion</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>multimodal</category>
<category>paper</category>
<category>papers</category>
<category>serving</category>
<category>vision</category>
</item>
<item>
<title>Safety Recovery in Reasoning Models Is Only a Few Early Steering Steps Away</title>
<link>https://tldr.takara.ai/p/2602.11096</link>
<guid>title:safety recovery in reasoning models is only a few early steering steps away</guid>
<pubDate>Wed, 11 Feb 2026 18:09:17 +0000</pubDate>
<description>Reinforcement learning (RL) based post-training for explicit chain-of-thought (e. g. , GRPO) improves the reasoning ability of multimodal large-scale reasoning models (MLRMs). But recent evidence shows that it can simultaneously degrade safety alignment and increase jailbreak success rates. We propose SafeThink, a lightweight inference-time defense that treats safety recovery as a satisficing constraint rather than a maximization objective. SafeThink monitors the evolving reasoning trace with a safety reward model and conditionally injects an optimized short corrective prefix (&quot;Wait, think safely&quot;) only when the safety threshold is violated.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>alignment</category>
<category>daily</category>
<category>huggingface</category>
<category>ml</category>
<category>multimodal</category>
<category>paper</category>
<category>papers</category>
<category>reasoning</category>
<category>rl</category>
<category>serving</category>
<category>vision</category>
</item>
<item>
<title>Found-RL: foundation model-enhanced reinforcement learning for autonomous driving</title>
<link>https://tldr.takara.ai/p/2602.10458</link>
<guid>title:found rl foundation model enhanced reinforcement learning for autonomous driving</guid>
<pubDate>Wed, 11 Feb 2026 02:56:04 +0000</pubDate>
<description>Reinforcement Learning (RL) has emerged as a dominant paradigm for end-to-end autonomous driving (AD). However, RL suffers from sample inefficiency and a lack of semantic interpretability in complex scenarios. Foundation Models, particularly Vision-Language Models (VLMs), can mitigate this by offering rich, context-aware knowledge, yet their high inference latency hinders deployment in high-frequency RL training loops. To bridge this gap, we present Found-RL, a platform tailored to efficiently enhance RL for AD using foundation models. A core innovation is the asynchronous batch inference framework, which decouples heavy VLM reasoning from the simulation loop, effectively resolving latency bottlenecks to support real-time learning. We introduce diverse supervision mechanisms: Value-Margin Regularization (VMR) and Advantage-Weighted Action Guidance (AWAG) to effectively distill expert-like VLM action suggestions into the RL policy.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>alignment</category>
<category>daily</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>reasoning</category>
<category>rl</category>
<category>serving</category>
<category>vision</category>
</item>
<item>
<title>Found-RL: foundation model-enhanced reinforcement learning for autonomous driving</title>
<link>https://arxiv.org/abs/2602.10458</link>
<guid>arxiv:2602.10458</guid>
<pubDate>Thu, 12 Feb 2026 05:00:00 +0000</pubDate>
<description>arXiv:2602. 10458v1 Announce Type: new Abstract: Reinforcement Learning (RL) has emerged as a dominant paradigm for end-to-end autonomous driving (AD). However, RL suffers from sample inefficiency and a lack of semantic interpretability in complex scenarios. Foundation Models, particularly Vision-Language Models (VLMs), can mitigate this by offering rich, context-aware knowledge, yet their high inference latency hinders deployment in high-frequency RL training loops. To bridge this gap, we present Found-RL, a platform tailored to efficiently enhance RL for AD using foundation models. A core innovation is the asynchronous batch inference framework, which decouples heavy VLM reasoning from the simulation loop, effectively resolving latency bottlenecks to support real-time learning.</description>
<source url="https://rss.arxiv.org/rss/cs.AI">arxiv</source>
<category>ai</category>
<category>alignment</category>
<category>arxiv</category>
<category>cs.ai</category>
<category>cs.lg</category>
<category>llm</category>
<category>paper</category>
<category>papers</category>
<category>reasoning</category>
<category>research</category>
<category>rl</category>
<category>serving</category>
<category>vision</category>
</item>
<item>
<title>See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch</title>
<link>https://tldr.takara.ai/p/2602.10814</link>
<guid>title:see plan snap evaluating multimodal gui agents in scratch</guid>
<pubDate>Wed, 11 Feb 2026 12:54:53 +0000</pubDate>
<description>Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spanning four distinct problem categories: Create, Debug, Extend, and Compute. To rigorously diagnose the source of agent failures, the benchmark employs two complementary interaction modes: primitive mode requires fine-grained drag-and-drop manipulation to directly assess visuomotor control, while composite mode uses high-level semantic APIs to disentangle program reasoning from GUI execution. To ensure reliable assessment, we propose an execution-based evaluation protocol that validates the functional correctness of the constructed Scratch programs through runtime tests within the browser environment. Extensive experiments across state-of-the-art multimodal language models and GUI agents reveal a substantial reasoning--acting gap, highlighting persistent challenges in fine-grained GUI manipulation despite strong planning capabilities.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>agents</category>
<category>daily</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>multimodal</category>
<category>paper</category>
<category>papers</category>
<category>reasoning</category>
<category>rl</category>
</item>
<item>
<title>When to Memorize and When to Stop: Gated Recurrent Memory for Long-Context Reasoning</title>
<link>https://tldr.takara.ai/p/2602.10560</link>
<guid>title:when to memorize and when to stop gated recurrent memory for long context reasoning</guid>
<pubDate>Wed, 11 Feb 2026 06:14:53 +0000</pubDate>
<description>While reasoning over long context is crucial for various real-world applications, it remains challenging for large language models (LLMs) as they suffer from performance degradation as the context length grows. Recent work MemAgent has tried to tackle this by processing context chunk-by-chunk in an RNN-like loop and updating a textual memory for final answering. However, this naive recurrent memory update faces two crucial drawbacks: (i) memory can quickly explode because it can update indiscriminately, even on evidence-free chunks; and (ii) the loop lacks an exit mechanism, leading to unnecessary computation after even sufficient evidence is collected. To address these issues, we propose GRU-Mem, which incorporates two text-controlled gates for more stable and efficient long-context reasoning. Specifically, in GRU-Mem, the memory only updates when the update gate is open and the recurrent loop will exit immediately once the exit gate is open. To endow the model with such capabilities, we introduce two reward signals $r^{\text{update}}$ and $r^{\text{exit}}$ within end-to-end RL, rewarding the correct updating and exiting behaviors respectively.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>agents</category>
<category>daily</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>reasoning</category>
<category>rl</category>
<category>serving</category>
</item>
<item>
<title>C^2ROPE: Causal Continuous Rotary Positional Encoding for 3D Large Multimodal-Models Reasoning</title>
<link>https://tldr.takara.ai/p/2602.10551</link>
<guid>title:c 2rope causal continuous rotary positional encoding for 3d large multimodal models reasoning</guid>
<pubDate>Wed, 11 Feb 2026 05:50:17 +0000</pubDate>
<description>Recent advances in 3D Large Multimodal Models (LMMs) built on Large Language Models (LLMs) have established the alignment of 3D visual features with LLM representations as the dominant paradigm. However, the inherited Rotary Position Embedding (RoPE) introduces limitations for multimodal processing. Specifically, applying 1D temporal positional indices disrupts the continuity of visual features along the column dimension, resulting in spatial locality loss. Moreover, RoPE follows the prior that temporally closer image tokens are more causally related, leading to long-term decay in attention allocation and causing the model to progressively neglect earlier visual tokens as the sequence length increases. To address these issues, we propose C^2RoPE, an improved RoPE that explicitly models local spatial Continuity and spatial Causal relationships for visual processing. C^2RoPE introduces a spatio-temporal continuous positional embedding mechanism for visual tokens.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>alignment</category>
<category>daily</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>multimodal</category>
<category>paper</category>
<category>papers</category>
<category>reasoning</category>
<category>rl</category>
</item>
<item>
<title>Search or Accelerate: Confidence-Switched Position Beam Search for Diffusion Language Models</title>
<link>https://tldr.takara.ai/p/2602.10953</link>
<guid>title:search or accelerate confidence switched position beam search for diffusion language models</guid>
<pubDate>Wed, 11 Feb 2026 15:41:09 +0000</pubDate>
<description>Diffusion Language Models (DLMs) generate text by iteratively denoising a masked sequence, repeatedly deciding which positions to commit at each step. Standard decoding follows a greedy rule: unmask the most confident positions, yet this local choice can lock the model into a suboptimal unmasking order, especially on reasoning-heavy prompts. We present SOAR, a training-free decoding algorithm that adapts its behavior to the model's uncertainty. When confidence is low, SOAR briefly widens the search over alternative unmasking decisions to avoid premature commitments; when confidence is high, it collapses the search and decodes many positions in parallel to reduce the number of denoising iterations. Across mathematical reasoning and code generation benchmarks (GSM8K, MBPP, HumanEval) on Dream-7B and LLaDA-8B, SOAR improves generation quality while maintaining competitive inference speed, offering a practical way to balance quality and efficiency in DLM decoding.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>diffusion</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>reasoning</category>
<category>serving</category>
</item>
<item>
<title>Rotary Positional Embeddings as Phase Modulation: Theoretical Bounds on the RoPE Base for Long-Context Transformers</title>
<link>https://tldr.takara.ai/p/2602.10959</link>
<guid>title:rotary positional embeddings as phase modulation theoretical bounds on the rope base for long context transformers</guid>
<pubDate>Wed, 11 Feb 2026 15:50:07 +0000</pubDate>
<description>Rotary positional embeddings (RoPE) are widely used in large language models to encode token positions through multiplicative rotations, yet their behavior at long context lengths remains poorly characterized. In this work, we reinterpret RoPE as phase modulation applied to a bank of complex oscillators, enabling analysis through classical signal processing theory. Under this formulation, we derive principled lower bounds on the RoPE base parameter that are necessary to preserve positional coherence over a target context length. These include a fundamental aliasing bound, analogous to a Nyquist limit, and a DC-component stability bound that constrains phase drift in low-frequency positional modes. We further extend this analysis to deep transformers, showing that repeated rotary modulation across layers compounds angular misalignment, tightening the base requirement as depth increases. Complementing these results, we derive a precision-dependent upper bound on the RoPE base arising from finite floating-point resolution.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>alignment</category>
<category>daily</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>rl</category>
</item>
<item>
<title>RePO: Bridging On-Policy Learning and Off-Policy Knowledge through Rephrasing Policy Optimization</title>
<link>https://tldr.takara.ai/p/2602.10819</link>
<guid>title:repo bridging on policy learning and off policy knowledge through rephrasing policy optimization</guid>
<pubDate>Wed, 11 Feb 2026 13:02:40 +0000</pubDate>
<description>Aligning large language models (LLMs) on domain-specific data remains a fundamental challenge. Supervised fine-tuning (SFT) offers a straightforward way to inject domain knowledge but often degrades the model's generality. In contrast, on-policy reinforcement learning (RL) preserves generality but fails to effectively assimilate hard samples that exceed the model's current reasoning level. Recent off-policy RL attempts improve hard sample utilization, yet they suffer from severe training instability due to the forced distribution shift toward off-policy knowledge. To reconcile effective off-policy knowledge absorption with the stability of on-policy RL, we propose Rephrasing Policy Optimization (RePO). In RePO, the policy model is prompted to first comprehend off-policy knowledge and then rephrase it into trajectories that conform to its own stylistic and parametric distribution.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>reasoning</category>
<category>rl</category>
</item>
<item>
<title>Why Does RL Generalize Better Than SFT? A Data-Centric Perspective on VLM Post-Training</title>
<link>https://tldr.takara.ai/p/2602.10815</link>
<guid>title:why does rl generalize better than sft a data centric perspective on vlm post training</guid>
<pubDate>Wed, 11 Feb 2026 12:55:15 +0000</pubDate>
<description>The adaptation of large-scale Vision-Language Models (VLMs) through post-training reveals a pronounced generalization gap: models fine-tuned with Reinforcement Learning (RL) consistently achieve superior out-of-distribution (OOD) performance compared to those trained with Supervised Fine-Tuning (SFT). This paper posits a data-centric explanation for this phenomenon, contending that RL's generalization advantage arises from an implicit data filtering mechanism that inherently prioritizes medium-difficulty training samples. To test this hypothesis, we systematically evaluate the OOD generalization of SFT models across training datasets of varying difficulty levels. Our results confirm that data difficulty is a critical factor, revealing that training on hard samples significantly degrades OOD performance. Motivated by this finding, we introduce Difficulty-Curated SFT (DC-SFT), a straightforward method that explicitly filters the training set based on sample difficulty. Experiments show that DC-SFT not only substantially enhances OOD generalization over standard SFT, but also surpasses the performance of RL-based training, all while providing greater stability and computational efficiency.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>rl</category>
<category>vision</category>
</item>
<item>
<title>Token-Efficient Change Detection in LLM APIs</title>
<link>https://tldr.takara.ai/p/2602.11083</link>
<guid>title:token efficient change detection in llm apis</guid>
<pubDate>Wed, 11 Feb 2026 17:48:29 +0000</pubDate>
<description>Remote change detection in LLMs is a difficult problem. Existing methods are either too expensive for deployment at scale, or require initial white-box access to model weights or grey-box access to log probabilities. We aim to achieve both low cost and strict black-box operation, observing only output tokens. Our approach hinges on specific inputs we call Border Inputs, for which there exists more than one output top token. From a statistical perspective, optimal change detection depends on the model's Jacobian and the Fisher information of the output distribution. Analyzing these quantities in low-temperature regimes shows that border inputs enable powerful change detection tests.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>reasoning</category>
</item>
<item>
<title>MoToRec: Sparse-Regularized Multimodal Tokenization for Cold-Start Recommendation</title>
<link>https://tldr.takara.ai/p/2602.11062</link>
<guid>title:motorec sparse regularized multimodal tokenization for cold start recommendation</guid>
<pubDate>Wed, 11 Feb 2026 17:31:14 +0000</pubDate>
<description>Graph neural networks (GNNs) have revolutionized recommender systems by effectively modeling complex user-item interactions, yet data sparsity and the item cold-start problem significantly impair performance, particularly for new items with limited or no interaction history. While multimodal content offers a promising solution, existing methods result in suboptimal representations for new items due to noise and entanglement in sparse data. To address this, we transform multimodal recommendation into discrete semantic tokenization. We present Sparse-Regularized Multimodal Tokenization for Cold-Start Recommendation (MoToRec), a framework centered on a sparsely-regularized Residual Quantized Variational Autoencoder (RQ-VAE) that generates a compositional semantic code of discrete, interpretable tokens, promoting disentangled representations. MoToRec's architecture is enhanced by three synergistic components: (1) a sparsely-regularized RQ-VAE that promotes disentangled representations, (2) a novel adaptive rarity amplification that promotes prioritized learning for cold-start items, and (3) a hierarchical multi-source graph encoder for robust signal fusion with collaborative signals. Extensive experiments on three large-scale datasets demonstrate MoToRec's superiority over state-of-the-art methods in both overall and cold-start scenarios.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>ml</category>
<category>multimodal</category>
<category>paper</category>
<category>papers</category>
<category>rl</category>
</item>
<item>
<title>Variational Optimality of Föllmer Processes in Generative Diffusions</title>
<link>https://tldr.takara.ai/p/2602.10989</link>
<guid>title:variational optimality of f llmer processes in generative diffusions</guid>
<pubDate>Wed, 11 Feb 2026 16:15:19 +0000</pubDate>
<description>We construct and analyze generative diffusions that transport a point mass to a prescribed target distribution over a finite time horizon using the stochastic interpolant framework. The drift is expressed as a conditional expectation that can be estimated from independent samples without simulating stochastic processes. We show that the diffusion coefficient can be tuned \emph{a~posteriori} without changing the time-marginal distributions. Among all such tunings, we prove that minimizing the impact of estimation error on the path-space Kullback--Leibler divergence selects, in closed form, a Föllmer process -- a diffusion whose path measure minimizes relative entropy with respect to a reference process determined by the interpolation schedules alone. This yields a new variational characterization of Föllmer processes, complementing classical formulations via Schrödinger bridges and stochastic control. We further establish that, under this optimal diffusion coefficient, the path-space Kullback--Leibler divergence becomes independent of the interpolation schedule, rendering different schedules statistically equivalent in this variational sense.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>diffusion</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
</item>
<item>
<title>FeatureBench: Benchmarking Agentic Coding for Complex Feature Development</title>
<link>https://tldr.takara.ai/p/2602.10975</link>
<guid>title:featurebench benchmarking agentic coding for complex feature development</guid>
<pubDate>Wed, 11 Feb 2026 16:06:32 +0000</pubDate>
<description>Agents powered by large language models (LLMs) are increasingly adopted in the software industry, contributing code as collaborators or even autonomous developers. As their presence grows, it becomes important to assess the current boundaries of their coding abilities. Existing agentic coding benchmarks, however, cover a limited task scope, e. g. , bug fixing within a single pull request (PR), and often rely on non-executable evaluations or lack an automated approach for continually updating the evaluation coverage. To address such issues, we propose FeatureBench, a benchmark designed to evaluate agentic coding performance in end-to-end, feature-oriented software development.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>agents</category>
<category>daily</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
</item>
<item>
<title>Towards Learning a Generalizable 3D Scene Representation from 2D Observations</title>
<link>https://tldr.takara.ai/p/2602.10943</link>
<guid>title:towards learning a generalizable 3d scene representation from 2d observations</guid>
<pubDate>Wed, 11 Feb 2026 15:22:41 +0000</pubDate>
<description>We introduce a Generalizable Neural Radiance Field approach for predicting 3D workspace occupancy from egocentric robot observations. Unlike prior methods operating in camera-centric coordinates, our model constructs occupancy representations in a global workspace frame, making it directly applicable to robotic manipulation. The model integrates flexible source views and generalizes to unseen object arrangements without scene-specific finetuning. We demonstrate the approach on a humanoid robot and evaluate predicted geometry against 3D sensor ground truth. Trained on 40 real scenes, our model achieves 26mm reconstruction error, including occluded regions, validating its ability to infer complete 3D occupancy beyond traditional stereo vision methods.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>robotics</category>
<category>vision</category>
</item>
<item>
<title>Self-Supervised Learning for Speaker Recognition: A study and review</title>
<link>https://tldr.takara.ai/p/2602.10829</link>
<guid>title:self supervised learning for speaker recognition a study and review</guid>
<pubDate>Wed, 11 Feb 2026 13:16:07 +0000</pubDate>
<description>Deep learning models trained in a supervised setting have revolutionized audio and speech processing. However, their performance inherently depends on the quantity of human-annotated data, making them costly to scale and prone to poor generalization under unseen conditions. To address these challenges, Self-Supervised Learning (SSL) has emerged as a promising paradigm, leveraging vast amounts of unlabeled data to learn relevant representations. The application of SSL for Automatic Speech Recognition (ASR) has been extensively studied, but research on other downstream tasks, notably Speaker Recognition (SR), remains in its early stages. This work describes major SSL instance-invariance frameworks (e. g.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>rl</category>
<category>vision</category>
</item>
<item>
<title>From Representational Complementarity to Dual Systems: Synergizing VLM and Vision-Only Backbones for End-to-End Driving</title>
<link>https://tldr.takara.ai/p/2602.10719</link>
<guid>title:from representational complementarity to dual systems synergizing vlm and vision only backbones for end to end driving</guid>
<pubDate>Wed, 11 Feb 2026 10:25:05 +0000</pubDate>
<description>Vision-Language-Action (VLA) driving augments end-to-end (E2E) planning with language-enabled backbones, yet it remains unclear what changes beyond the usual accuracy--cost trade-off. We revisit this question with 3--RQ analysis in RecogDrive by instantiating the system with a full VLM and vision-only backbones, all under an identical diffusion Transformer planner. RQ1: At the backbone level, the VLM can introduce additional subspaces upon the vision-only backbones. RQ2: This unique subspace leads to a different behavioral in some long-tail scenario: the VLM tends to be more aggressive whereas ViT is more conservative, and each decisively wins on about 2--3% of test scenarios; With an oracle that selects, per scenario, the better trajectory between the VLM and ViT branches, we obtain an upper bound of 93. 58 PDMS. RQ3: To fully harness this observation, we propose HybridDriveVLA, which runs both ViT and VLM branches and selects between their endpoint trajectories using a learned scorer, improving PDMS to 92.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>diffusion</category>
<category>huggingface</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>vision</category>
</item>
<item>
<title>(MGS)$^2$-Net: Unifying Micro-Geometric Scale and Macro-Geometric Structure for Cross-View Geo-Localization</title>
<link>https://tldr.takara.ai/p/2602.10704</link>
<guid>title:mgs 2 net unifying micro geometric scale and macro geometric structure for cross view geo localization</guid>
<pubDate>Wed, 11 Feb 2026 10:03:31 +0000</pubDate>
<description>Cross-view geo-localization (CVGL) is pivotal for GNSS-denied UAV navigation but remains brittle under the drastic geometric misalignment between oblique aerial views and orthographic satellite references. Existing methods predominantly operate within a 2D manifold, neglecting the underlying 3D geometry where view-dependent vertical facades (macro-structure) and scale variations (micro-scale) severely corrupt feature alignment. To bridge this gap, we propose (MGS)$^2$, a geometry-grounded framework. The core of our innovation is the Macro-Geometric Structure Filtering (MGSF) module. Unlike pixel-wise matching sensitive to noise, MGSF leverages dilated geometric gradients to physically filter out high-frequency facade artifacts while enhancing the view-invariant horizontal plane, directly addressing the domain shift. To guarantee robust input for this structural filtering, we explicitly incorporate a Micro-Geometric Scale Adaptation (MGSA) module.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>alignment</category>
<category>daily</category>
<category>huggingface</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>rl</category>
</item>
<item>
<title>TwiFF (Think With Future Frames): A Large-Scale Dataset for Dynamic Visual Reasoning</title>
<link>https://tldr.takara.ai/p/2602.10675</link>
<guid>title:twiff think with future frames a large scale dataset for dynamic visual reasoning</guid>
<pubDate>Wed, 11 Feb 2026 09:20:04 +0000</pubDate>
<description>Visual Chain-of-Thought (VCoT) has emerged as a promising paradigm for enhancing multimodal reasoning by integrating visual perception into intermediate reasoning steps. However, existing VCoT approaches are largely confined to static scenarios and struggle to capture the temporal dynamics essential for tasks such as instruction, prediction, and camera motion. To bridge this gap, we propose TwiFF-2. 7M, the first large-scale, temporally grounded VCoT dataset derived from $2. 7$ million video clips, explicitly designed for dynamic visual question and answer. Accompanying this, we introduce TwiFF-Bench, a high-quality evaluation benchmark of $1,078$ samples that assesses both the plausibility of reasoning trajectories and the correctness of final answers in open-ended dynamic settings.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>ml</category>
<category>multimodal</category>
<category>paper</category>
<category>papers</category>
<category>reasoning</category>
</item>
<item>
<title>UMEM: Unified Memory Extraction and Management Framework for Generalizable Memory</title>
<link>https://tldr.takara.ai/p/2602.10652</link>
<guid>title:umem unified memory extraction and management framework for generalizable memory</guid>
<pubDate>Wed, 11 Feb 2026 08:58:41 +0000</pubDate>
<description>Self-evolving memory serves as the trainable parameters for Large Language Models (LLMs)-based agents, where extraction (distilling insights from experience) and management (updating the memory bank) must be tightly coordinated. Existing methods predominately optimize memory management while treating memory extraction as a static process, resulting in poor generalization, where agents accumulate instance-specific noise rather than robust memories. To address this, we propose Unified Memory Extraction and Management (UMEM), a self-evolving agent framework that jointly optimizes a Large Language Model to simultaneous extract and manage memories. To mitigate overfitting to specific instances, we introduce Semantic Neighborhood Modeling and optimize the model with a neighborhood-level marginal utility reward via GRPO. This approach ensures memory generalizability by evaluating memory utility across clusters of semantically related queries. Extensive experiments across five benchmarks demonstrate that UMEM significantly outperforms highly competitive baselines, achieving up to a 10.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>agents</category>
<category>daily</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
</item>
<item>
<title>SCRAPL: Scattering Transform with Random Paths for Machine Learning</title>
<link>https://tldr.takara.ai/p/2602.11145</link>
<guid>title:scrapl scattering transform with random paths for machine learning</guid>
<pubDate>Wed, 11 Feb 2026 18:57:08 +0000</pubDate>
<description>The Euclidean distance between wavelet scattering transform coefficients (known as paths) provides informative gradients for perceptual quality assessment of deep inverse problems in computer vision, speech, and audio processing. However, these transforms are computationally expensive when employed as differentiable loss functions for stochastic gradient descent due to their numerous paths, which significantly limits their use in neural network training. Against this problem, we propose &quot;Scattering transform with Random Paths for machine Learning&quot; (SCRAPL): a stochastic optimization scheme for efficient evaluation of multivariable scattering transforms. We implement SCRAPL for the joint time-frequency scattering transform (JTFS) which demodulates spectrotemporal patterns at multiple scales and rates, allowing a fine characterization of intermittent auditory textures. We apply SCRAPL to differentiable digital signal processing (DDSP), specifically, unsupervised sound matching of a granular synthesizer and the Roland TR-808 drum machine. We also propose an initialization heuristic based on importance sampling, which adapts SCRAPL to the perceptual content of the dataset, improving neural network convergence and evaluation performance.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>vision</category>
</item>
<item>
<title>Enhancing YOLOv11n for Reliable Child Detection in Noisy Surveillance Footage</title>
<link>https://tldr.takara.ai/p/2602.10592</link>
<guid>title:enhancing yolov11n for reliable child detection in noisy surveillance footage</guid>
<pubDate>Wed, 11 Feb 2026 07:27:47 +0000</pubDate>
<description>This paper presents a practical and lightweight solution for enhancing child detection in low-quality surveillance footage, a critical component in real-world missing child alert and daycare monitoring systems. Building upon the efficient YOLOv11n architecture, we propose a deployment-ready pipeline that improves detection under challenging conditions including occlusion, small object size, low resolution, motion blur, and poor lighting commonly found in existing CCTV infrastructures. Our approach introduces a domain-specific augmentation strategy that synthesizes realistic child placements using spatial perturbations such as partial visibility, truncation, and overlaps, combined with photometric degradations including lighting variation and noise. To improve recall of small and partially occluded instances, we integrate Slicing Aided Hyper Inference (SAHI) at inference time. All components are trained and evaluated on a filtered, child-only subset of the Roboflow Daycare dataset. Compared to the baseline YOLOv11n, our enhanced system achieves a mean Average Precision at 0.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>rl</category>
<category>serving</category>
</item>
<item>
<title>LLM-Based Scientific Equation Discovery via Physics-Informed Token-Regularized Policy Optimization</title>
<link>https://tldr.takara.ai/p/2602.10576</link>
<guid>title:llm based scientific equation discovery via physics informed token regularized policy optimization</guid>
<pubDate>Wed, 11 Feb 2026 07:02:23 +0000</pubDate>
<description>Symbolic regression aims to distill mathematical equations from observational data. Recent approaches have successfully leveraged Large Language Models (LLMs) to generate equation hypotheses, capitalizing on their vast pre-trained scientific priors. However, existing frameworks predominantly treat the LLM as a static generator, relying on prompt-level guidance to steer exploration. This paradigm fails to update the model's internal representations based on search feedback, often yielding physically inconsistent or mathematically redundant expressions. In this work, we propose PiT-PO (Physics-informed Token-regularized Policy Optimization), a unified framework that evolves the LLM into an adaptive generator via reinforcement learning. Central to PiT-PO is a dual-constraint mechanism that rigorously enforces hierarchical physical validity while simultaneously applying fine-grained, token-level penalties to suppress redundant structures.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>rl</category>
</item>
<item>
<title>In-the-Wild Model Organisms: Mitigating Undesirable Emergent Behaviors in Production LLM Post-Training via Data Attribution</title>
<link>https://tldr.takara.ai/p/2602.11079</link>
<guid>title:in the wild model organisms mitigating undesirable emergent behaviors in production llm post training via data attribution</guid>
<pubDate>Wed, 11 Feb 2026 17:45:31 +0000</pubDate>
<description>We propose activation-based data attribution, a method that traces behavioral changes in post-trained language models to responsible training datapoints. By computing activation-difference vectors for both test prompts and preference pairs and ranking by cosine similarity, we identify datapoints that cause specific behaviors and validate these attributions causally by retraining with modified data. Clustering behavior-datapoint similarity matrices also enables unsupervised discovery of emergent behaviors. Applying this to OLMo 2's production DPO training, we surfaced distractor-triggered compliance: a harmful behavior where the model complies with dangerous requests when benign formatting instructions are appended. Filtering top-ranked datapoints reduces this behavior by 63% while switching their labels achieves 78%. Our method outperforms gradient-based attribution and LLM-judge baselines while being over 10 times cheaper than both.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
</item>
<item>
<title>Linguistic Indicators of Early Cognitive Decline in the DementiaBank Pitt Corpus: A Statistical and Machine Learning Study</title>
<link>https://tldr.takara.ai/p/2602.11028</link>
<guid>title:linguistic indicators of early cognitive decline in the dementiabank pitt corpus a statistical and machine learning study</guid>
<pubDate>Wed, 11 Feb 2026 16:53:57 +0000</pubDate>
<description>Background: Subtle changes in spontaneous language production are among the earliest indicators of cognitive decline. Identifying linguistically interpretable markers of dementia can support transparent and clinically grounded screening approaches. Methods: This study analyzes spontaneous speech transcripts from the DementiaBank Pitt Corpus using three linguistic representations: raw cleaned text, a part-of-speech (POS)-enhanced representation combining lexical and grammatical information, and a POS-only syntactic representation. Logistic regression and random forest models were evaluated under two protocols: transcript-level train-test splits and subject-level five-fold cross-validation to prevent speaker overlap. Model interpretability was examined using global feature importance, and statistical validation was conducted using Mann-Whitney U tests with Cliff's delta effect sizes. Results: Across representations, models achieved stable performance, with syntactic and grammatical features retaining strong discriminative power even in the absence of lexical content.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>rl</category>
</item>
<item>
<title>Statistical Inference and Learning for Shapley Additive Explanations (SHAP)</title>
<link>https://tldr.takara.ai/p/2602.10532</link>
<guid>title:statistical inference and learning for shapley additive explanations shap</guid>
<pubDate>Wed, 11 Feb 2026 05:01:47 +0000</pubDate>
<description>The SHAP (short for Shapley additive explanation) framework has become an essential tool for attributing importance to variables in predictive tasks. In model-agnostic settings, SHAP uses the concept of Shapley values from cooperative game theory to fairly allocate credit to the features in a vector $X$ based on their contribution to an outcome $Y$. While the explanations offered by SHAP are local by nature, learners often need global measures of feature importance in order to improve model explainability and perform feature selection. The most common approach for converting these local explanations into global ones is to compute either the mean absolute SHAP or mean squared SHAP. However, despite their ubiquity, there do not exist approaches for performing statistical inference on these quantities. In this paper, we take a semi-parametric approach for calibrating confidence in estimates of the $p$th powers of Shapley additive explanations.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>rl</category>
<category>serving</category>
</item>
<item>
<title>LaSSM: Efficient Semantic-Spatial Query Decoding via Local Aggregation and State Space Models for 3D Instance Segmentation</title>
<link>https://tldr.takara.ai/p/2602.11007</link>
<guid>title:lassm efficient semantic spatial query decoding via local aggregation and state space models for 3d instance segmentation</guid>
<pubDate>Wed, 11 Feb 2026 16:34:12 +0000</pubDate>
<description>Query-based 3D scene instance segmentation from point clouds has attained notable performance. However, existing methods suffer from the query initialization dilemma due to the sparse nature of point clouds and rely on computationally intensive attention mechanisms in query decoders. We accordingly introduce LaSSM, prioritizing simplicity and efficiency while maintaining competitive performance. Specifically, we propose a hierarchical semantic-spatial query initializer to derive the query set from superpoints by considering both semantic cues and spatial distribution, achieving comprehensive scene coverage and accelerated convergence. We further present a coordinate-guided state space model (SSM) decoder that progressively refines queries. The novel decoder features a local aggregation scheme that restricts the model to focus on geometrically coherent regions and a spatial dual-path SSM block to capture underlying dependencies within the query set by integrating associated coordinates information.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>rl</category>
</item>
<item>
<title>Sample Efficient Generative Molecular Optimization with Joint Self-Improvement</title>
<link>https://tldr.takara.ai/p/2602.10984</link>
<guid>title:sample efficient generative molecular optimization with joint self improvement</guid>
<pubDate>Wed, 11 Feb 2026 16:13:07 +0000</pubDate>
<description>Generative molecular optimization aims to design molecules with properties surpassing those of existing compounds. However, such candidates are rare and expensive to evaluate, yielding sample efficiency essential. Additionally, surrogate models introduced to predict molecule evaluations, suffer from distribution shift as optimization drives candidates increasingly out-of-distribution. To address these challenges, we introduce Joint Self-Improvement, which benefits from (i) a joint generative-predictive model and (ii) a self-improving sampling scheme. The former aligns the generator with the surrogate, alleviating distribution shift, while the latter biases the generative part of the joint model using the predictive one to efficiently generate optimized molecules at inference-time. Experiments across offline and online molecular optimization benchmarks demonstrate that Joint Self-Improvement outperforms state-of-the-art methods under limited evaluation budgets.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>daily</category>
<category>huggingface</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
<category>serving</category>
</item>
<item>
<title>MERIT Feedback Elicits Better Bargaining in LLM Negotiators</title>
<link>https://tldr.takara.ai/p/2602.10467</link>
<guid>title:merit feedback elicits better bargaining in llm negotiators</guid>
<pubDate>Wed, 11 Feb 2026 03:09:45 +0000</pubDate>
<description>Bargaining is often regarded as a logical arena rather than an art or a matter of intuition, yet Large Language Models (LLMs) still struggle to navigate it due to limited strategic depth and difficulty adapting to complex human factors. Current benchmarks rarely capture this limitation. To bridge this gap, we present an utility feedback centric framework. Our contributions are: (i) AgoraBench, a new benchmark spanning nine challenging settings (e. g. , deception, monopoly) that supports diverse strategy modeling; (ii) human-aligned, economically grounded metrics derived from utility theory.</description>
<source url="https://papers.takara.ai/api/feed">huggingface</source>
<category>agents</category>
<category>daily</category>
<category>huggingface</category>
<category>llm</category>
<category>ml</category>
<category>paper</category>
<category>papers</category>
</item>
</channel>
</rss>