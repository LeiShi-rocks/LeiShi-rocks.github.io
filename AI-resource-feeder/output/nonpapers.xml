<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
<title>AI News &amp; Posts</title>
<link>https://example.com/ai-trend-feed</link>
<description>Top daily AI labs, blogs, and project updates</description>
<lastBuildDate>Sun, 22 Feb 2026 08:44:56 +0000</lastBuildDate>
<item>
<title>Anthropic and Infosys collaborate to build AI agents for telecommunications and other regulated industries</title>
<link>https://www.anthropic.com/news/anthropic-infosys</link>
<guid>title:anthropic and infosys collaborate to build ai agents for telecommunications and other regulated industries</guid>
<pubDate>Sun, 22 Feb 2026 08:44:46 +0000</pubDate>
<description>Anthropic and Infosys , a global leader in next-generation digital services and consulting founded and headquartered in Bengaluru, today announced a collaboration to develop and deliver enterprise AI solutions across telecommunications, financial services, manufacturing, and software development. The collaboration integrates Anthropic‚Äôs Claude models and Claude Code with Infosys Topaz , an AI-first set of services, solutions, and platforms using generative and agentic AI technologies, to help companies speed up software development and adopt AI with the governance and transparency that regulated industries require. India is the second-largest market for Claude.ai, home to a developer community doing some of the most technically intense AI work we see anywhere: nearly half of Claude usage in India involves building applications, modernizing systems, and shipping production software. Infosys is one of the first partners in Anthropic‚Äôs expanded presence in India .</description>
<source url="https://www.anthropic.com/news">anthropic</source>
<category>agents</category>
<category>anthropic</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>rl</category>
<category>safety</category>
</item>
<item>
<title>Anthropic raises $30 billion in Series G funding at $380 billion post-money valuation</title>
<link>https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation</link>
<guid>title:anthropic raises 30 billion in series g funding at 380 billion post money valuation</guid>
<pubDate>Sun, 22 Feb 2026 08:44:41 +0000</pubDate>
<description>We have raised $30 billion in Series G funding led by GIC and Coatue, valuing Anthropic at $380 billion post-money. The round was co-led by D. E. Shaw Ventures, Dragoneer, Founders Fund, ICONIQ, and MGX. The investment will fuel the frontier research, product development, and infrastructure expansions that have made Anthropic the market leader in enterprise AI and coding. Significant investors in this round include: Accel, Addition, Alpha Wave Global, Altimeter, AMP PBC, Appaloosa LP, Baillie Gifford, Bessemer Venture Partners, affiliated funds of BlackRock, Blackstone, D1 Capital Partners, Fidelity Management &amp; Research Company, General Catalyst, Greenoaks, Growth Equity at Goldman Sachs Alternatives, Insight Partners, Jane Street, JPMorganChase through its Security and Resiliency Initiative and Growth Equity Partners, Lightspeed Venture Partners, Menlo Ventures, Morgan Stanley Investment Management, NX1 Capital, Qatar Investment Authority (QIA), Sands Capital, Sequoia Capital, Temasek, TowerBrook, TPG, Whale Rock Capital, and XN.</description>
<source url="https://www.anthropic.com/news">anthropic</source>
<category>anthropic</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>rl</category>
<category>safety</category>
</item>
<item>
<title>Introducing Claude Opus 4.6</title>
<link>https://www.anthropic.com/news/claude-opus-4-6</link>
<guid>title:introducing claude opus 4 6</guid>
<pubDate>Sun, 22 Feb 2026 08:44:35 +0000</pubDate>
<description>We‚Äôre upgrading our smartest model. The new Claude Opus 4. 6 improves on its predecessor‚Äôs coding skills. It plans more carefully, sustains agentic tasks for longer, can operate more reliably in larger codebases, and has better code review and debugging skills to catch its own mistakes. And, in a first for our Opus-class models, Opus 4. 6 features a 1M token context window in beta 1 .</description>
<source url="https://www.anthropic.com/news">anthropic</source>
<category>agents</category>
<category>anthropic</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>safety</category>
</item>
<item>
<title>Newsroom</title>
<link>https://www.anthropic.com/news</link>
<guid>title:newsroom</guid>
<pubDate>Sun, 22 Feb 2026 08:44:30 +0000</pubDate>
<description>Sonnet 4. 6 delivers frontier performance across coding, agents, and professional work at scale. We‚Äôre upgrading our smartest model. Across agentic coding, computer use, tool use, search, and finance, Opus 4. 6 is an industry-leading model, often by wide margin. We‚Äôve made a choice: Claude will remain ad-free.</description>
<source url="https://www.anthropic.com/news">anthropic</source>
<category>agents</category>
<category>anthropic</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>safety</category>
</item>
<item>
<title>Anthropic and the Government of Rwanda sign MOU for AI in health and education</title>
<link>https://www.anthropic.com/news/anthropic-rwanda-mou</link>
<guid>title:anthropic and the government of rwanda sign mou for ai in health and education</guid>
<pubDate>Sun, 22 Feb 2026 08:44:44 +0000</pubDate>
<description>The Government of Rwanda and Anthropic have signed a three-year Memorandum of Understanding to formalize and expand our partnership, bringing AI to Rwanda‚Äôs education, health, and public sector systems. This agreement builds on the ALX education partnership we announced in November 2025 and marks the first time Anthropic has formalized a multi-sector partnership through a government MOU on the African continent. Our collaboration spans three areas: ‚ÄúThis partnership with Anthropic is an important milestone in Rwanda‚Äôs AI journey. Our goal is to continue to design and deploy AI solutions that can be applied at a national level to strengthen education, advance health outcomes, and enhance governance with an emphasis on our context,‚Äù said Paula Ingabire, Minister of Information and Communications Technology (ICT) and Innovation in Rwanda.</description>
<source url="https://www.anthropic.com/news">anthropic</source>
<category>anthropic</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>safety</category>
</item>
<item>
<title>How NVIDIA Extreme Hardware-Software Co-Design Delivered a Large Inference Boost for Sarvam AI‚Äôs Sovereign Models</title>
<link>https://developer.nvidia.com/blog/how-nvidia-extreme-hardware-software-co-design-delivered-a-large-inference-boost-for-sarvam-ais-sovereign-models/</link>
<guid>title:how nvidia extreme hardware software co design delivered a large inference boost for sarvam ai s sovereign models</guid>
<pubDate>Wed, 18 Feb 2026 16:00:00 +0000</pubDate>
<description>As global AI adoption accelerates, developers face a growing challenge: delivering large language model (LLM) performance that meets real-world latency and cost...</description>
<source url="https://developer.nvidia.com/blog/feed">nvidia</source>
<category>agentic ai / generative ai</category>
<category>blackwell</category>
<category>data center / cloud</category>
<category>data science</category>
<category>h100</category>
<category>hardware</category>
<category>infra</category>
<category>llm</category>
<category>nemo</category>
<category>nemotron</category>
<category>nonpaper</category>
<category>nvidia</category>
<category>nvidia inception</category>
<category>rl</category>
<category>serving</category>
<category>training</category>
</item>
<item>
<title>Making frontier cybersecurity capabilities available to defenders</title>
<link>https://www.anthropic.com/news/claude-code-security</link>
<guid>title:making frontier cybersecurity capabilities available to defenders</guid>
<pubDate>Sun, 22 Feb 2026 08:44:43 +0000</pubDate>
<description>Claude Code Security , a new capability built into Claude Code on the web, is now available in a limited research preview. It scans codebases for security vulnerabilities and suggests targeted software patches for human review, allowing teams to find and fix security issues that traditional methods often miss. Security teams face a common challenge: too many software vulnerabilities and not enough people to address them. Existing analysis tools help, but only to a point, as they usually look for known patterns. Finding the subtle, context-dependent vulnerabilities that are often exploited by attackers requires skilled human researchers, who are dealing with ever-expanding backlogs. AI is beginning to change that calculus.</description>
<source url="https://www.anthropic.com/news">anthropic</source>
<category>anthropic</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>safety</category>
</item>
<item>
<title>Claude is a space to think</title>
<link>https://www.anthropic.com/news/claude-is-a-space-to-think</link>
<guid>title:claude is a space to think</guid>
<pubDate>Sun, 22 Feb 2026 08:44:40 +0000</pubDate>
<description>There are many good places for advertising. A conversation with Claude is not one of them. Advertising drives competition, helps people discover new products, and allows services like email and social media to be offered for free. We‚Äôve run our own ad campaigns , and our AI models have, in turn, helped many of our customers in the advertising industry. But including ads in conversations with Claude would be incompatible with what we want Claude to be: a genuinely helpful assistant for work and for deep thinking.</description>
<source url="https://www.anthropic.com/news">anthropic</source>
<category>anthropic</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>safety</category>
</item>
<item>
<title>‚ÄúNo technology has me dreaming bigger than AI‚Äù</title>
<link>https://blog.google/company-news/inside-google/message-ceo/sundar-pichai-ai-impact-summit-2026/</link>
<guid>title:no technology has me dreaming bigger than ai</guid>
<pubDate>Thu, 19 Feb 2026 04:30:00 +0000</pubDate>
<description>a stylized design resembling the Ashoka Chakra with colorful network lines and text reading &quot;‡§≠‡§æ‡§∞‡§§ 2026 INDIA.&quot; A vertical line separates it from the Google logo on the right, all set against a light blue gradient background with a faint grid pattern.</description>
<source url="https://blog.google/technology/ai/rss/">google</source>
<category>a message from our ceo</category>
<category>ai</category>
<category>google</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>research</category>
</item>
<item>
<title>AI Impact Summit 2026</title>
<link>https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-collection/</link>
<guid>title:ai impact summit 2026</guid>
<pubDate>Thu, 19 Feb 2026 04:30:00 +0000</pubDate>
<description>A look at the partnerships and investments Google announced at the AI Impact Summit 2026.</description>
<source url="https://blog.google/technology/ai/rss/">google</source>
<category>ai</category>
<category>google</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>research</category>
</item>
<item>
<title>A new way to express yourself: Gemini can now create music</title>
<link>https://blog.google/innovation-and-ai/products/gemini-app/lyria-3/</link>
<guid>title:a new way to express yourself gemini can now create music</guid>
<pubDate>Wed, 18 Feb 2026 16:00:00 +0000</pubDate>
<description>Image showing sample tracks created with Lyria 3</description>
<source url="https://blog.google/technology/ai/rss/">google</source>
<category>ai</category>
<category>gemini app</category>
<category>google</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>research</category>
</item>
<item>
<title>AI Impact Summit 2026: How we‚Äôre partnering to make AI work for everyone</title>
<link>https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-india/</link>
<guid>title:ai impact summit 2026 how we re partnering to make ai work for everyone</guid>
<pubDate>Wed, 18 Feb 2026 10:30:00 +0000</pubDate>
<description>four people seated on a conference stage</description>
<source url="https://blog.google/technology/ai/rss/">google</source>
<category>ai</category>
<category>google</category>
<category>google in asia</category>
<category>google.org</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>research</category>
</item>
<item>
<title>Accelerating Data Processing with NVIDIA Multi-Instance GPU and NUMA Node Localization</title>
<link>https://developer.nvidia.com/blog/accelerating-data-processing-with-nvidia-multi-instance-gpu-and-numa-node-localization/</link>
<guid>title:accelerating data processing with nvidia multi instance gpu and numa node localization</guid>
<pubDate>Thu, 19 Feb 2026 17:30:00 +0000</pubDate>
<description>NVIDIA flagship data center GPUs in the NVIDIA Ampere, NVIDIA Hopper, and NVIDIA Blackwell families all feature non-uniform memory access (NUMA) behaviors, but...</description>
<source url="https://developer.nvidia.com/blog/feed">nvidia</source>
<category>agentic ai / generative ai</category>
<category>cuda c++</category>
<category>data analytics / processing</category>
<category>data center / cloud</category>
<category>hardware</category>
<category>infra</category>
<category>memory</category>
<category>multi-instance gpu (mig)</category>
<category>nonpaper</category>
<category>nvidia</category>
<category>simulation / modeling / design</category>
<category>training</category>
</item>
<item>
<title>Our 2026 Responsible AI Progress Report</title>
<link>https://blog.google/innovation-and-ai/products/responsible-ai-2026-report-ongoing-work/</link>
<guid>title:our 2026 responsible ai progress report</guid>
<pubDate>Tue, 17 Feb 2026 22:30:00 +0000</pubDate>
<description>an illustration of blue and white cubes</description>
<source url="https://blog.google/technology/ai/rss/">google</source>
<category>ai</category>
<category>google</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>research</category>
</item>
<item>
<title>Teaching AI to read a map</title>
<link>https://research.google/blog/teaching-ai-to-read-a-map/</link>
<guid>title:teaching ai to read a map</guid>
<pubDate>Tue, 17 Feb 2026 21:37:00 +0000</pubDate>
<description>Machine Perception</description>
<source url="https://research.google/blog/rss/">google-research</source>
<category>google-research</category>
<category>machine perception</category>
<category>models</category>
<category>nonpaper</category>
<category>open source models &amp; datasets</category>
<category>research</category>
<category>science</category>
</item>
<item>
<title>Build AI-Ready Knowledge Systems Using 5 Essential Multimodal RAG Capabilities</title>
<link>https://developer.nvidia.com/blog/build-ai-ready-knowledge-systems-using-5-essential-multimodal-rag-capabilities/</link>
<guid>title:build ai ready knowledge systems using 5 essential multimodal rag capabilities</guid>
<pubDate>Tue, 17 Feb 2026 18:00:00 +0000</pubDate>
<description>Enterprise data is inherently complex: real-world documents are multimodal, spanning text, tables, charts and graphs, images, diagrams, scanned pages, forms,...</description>
<source url="https://developer.nvidia.com/blog/feed">nvidia</source>
<category>agentic ai / generative ai</category>
<category>ai agent</category>
<category>data center / cloud</category>
<category>hardware</category>
<category>infra</category>
<category>llms</category>
<category>multimodal</category>
<category>nonpaper</category>
<category>nvidia</category>
<category>retrieval augmented generation (rag)</category>
<category>rl</category>
<category>training</category>
</item>
<item>
<title>Accelerating discovery in India through AI-powered science and education</title>
<link>https://deepmind.google/blog/accelerating-discovery-in-india-through-ai-powered-science-and-education/</link>
<guid>title:accelerating discovery in india through ai powered science and education</guid>
<pubDate>Tue, 17 Feb 2026 13:42:20 +0000</pubDate>
<description>Google DeepMind brings National Partnerships for AI initiative to India, scaling AI for science and education</description>
<source url="https://deepmind.google/blog/feed/basic/">deepmind</source>
<category>deepmind</category>
<category>lab</category>
<category>nonpaper</category>
<category>research</category>
<category>science</category>
</item>
<item>
<title>Unlock Massive Token Throughput with GPU Fractioning in NVIDIA Run:ai</title>
<link>https://developer.nvidia.com/blog/unlock-massive-token-throughput-with-gpu-fractioning-in-nvidia-runai/</link>
<guid>title:unlock massive token throughput with gpu fractioning in nvidia run ai</guid>
<pubDate>Wed, 18 Feb 2026 18:00:00 +0000</pubDate>
<description>As AI workloads scale, achieving high throughput, efficient resource usage, and predictable latency becomes essential. NVIDIA Run:ai addresses these challenges...</description>
<source url="https://developer.nvidia.com/blog/feed">nvidia</source>
<category>agentic ai / generative ai</category>
<category>ai inference</category>
<category>data center / cloud</category>
<category>data science</category>
<category>hardware</category>
<category>inference performance</category>
<category>infra</category>
<category>llms</category>
<category>nonpaper</category>
<category>nvidia</category>
<category>training</category>
</item>
<item>
<title>Topping the GPU MODE Kernel Leaderboard with NVIDIA cuda.compute</title>
<link>https://developer.nvidia.com/blog/topping-the-gpu-mode-kernel-leaderboard-with-nvidia-cuda-compute/</link>
<guid>title:topping the gpu mode kernel leaderboard with nvidia cuda compute</guid>
<pubDate>Wed, 18 Feb 2026 17:00:00 +0000</pubDate>
<description>Python dominates machine learning for its ergonomics, but writing truly fast GPU code has historically meant dropping into C++ to write custom kernels and to...</description>
<source url="https://developer.nvidia.com/blog/feed">nvidia</source>
<category>agentic ai / generative ai</category>
<category>cuda</category>
<category>data science</category>
<category>developer tools &amp; techniques</category>
<category>hardware</category>
<category>infra</category>
<category>nonpaper</category>
<category>nvidia</category>
<category>training</category>
</item>
<item>
<title>Scheduling in a changing world: Maximizing throughput with time-varying capacity</title>
<link>https://research.google/blog/scheduling-in-a-changing-world-maximizing-throughput-with-time-varying-capacity/</link>
<guid>title:scheduling in a changing world maximizing throughput with time varying capacity</guid>
<pubDate>Wed, 11 Feb 2026 10:34:00 +0000</pubDate>
<description>Algorithms &amp; Theory</description>
<source url="https://research.google/blog/rss/">google-research</source>
<category>algorithms &amp; theory</category>
<category>google-research</category>
<category>models</category>
<category>nonpaper</category>
<category>research</category>
<category>rl</category>
<category>science</category>
</item>
<item>
<title>R¬≤D¬≤: Scaling Multimodal Robot Learning with NVIDIA Isaac Lab</title>
<link>https://developer.nvidia.com/blog/r2d2-scaling-multimodal-robot-learning-with-nvidia-isaac-lab/</link>
<guid>title:r d scaling multimodal robot learning with nvidia isaac lab</guid>
<pubDate>Tue, 10 Feb 2026 18:30:00 +0000</pubDate>
<description>Building robust, intelligent robots requires testing them in complex environments. However, gathering data in the physical world is expensive, slow, and often...</description>
<source url="https://developer.nvidia.com/blog/feed">nvidia</source>
<category>ai foundation models</category>
<category>hardware</category>
<category>humanoid robots</category>
<category>infra</category>
<category>multimodal</category>
<category>nonpaper</category>
<category>nvidia</category>
<category>nvidia research</category>
<category>open source</category>
<category>physical ai</category>
<category>rl</category>
<category>robotics</category>
<category>robotics research and development digest (r¬≤d¬≤)</category>
<category>simulation / modeling / design</category>
<category>training</category>
</item>
<item>
<title>Gemini 3 Deep Think: Advancing science, research and engineering</title>
<link>https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/</link>
<guid>title:gemini 3 deep think advancing science research and engineering</guid>
<pubDate>Thu, 12 Feb 2026 16:13:00 +0000</pubDate>
<description>Gemini 3 Deep Think logo</description>
<source url="https://blog.google/technology/ai/rss/">google</source>
<category>ai</category>
<category>gemini models</category>
<category>google</category>
<category>google deepmind</category>
<category>google one</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>research</category>
</item>
<item>
<title>Beyond one-on-one: Authoring, simulating, and testing dynamic human-AI group conversations</title>
<link>https://research.google/blog/beyond-one-on-one-authoring-simulating-and-testing-dynamic-human-ai-group-conversations/</link>
<guid>title:beyond one on one authoring simulating and testing dynamic human ai group conversations</guid>
<pubDate>Tue, 10 Feb 2026 18:30:00 +0000</pubDate>
<description>Human-Computer Interaction and Visualization</description>
<source url="https://research.google/blog/rss/">google-research</source>
<category>google-research</category>
<category>human-computer interaction and visualization</category>
<category>machine intelligence</category>
<category>models</category>
<category>nonpaper</category>
<category>research</category>
<category>science</category>
</item>
<item>
<title>9 fun questions to try asking Google Photos</title>
<link>https://blog.google/products-and-platforms/products/photos/ask-button-ask-photos-tips/</link>
<guid>title:9 fun questions to try asking google photos</guid>
<pubDate>Tue, 10 Feb 2026 17:00:00 +0000</pubDate>
<description>A collage of outdoor images, a blue icon that say &quot;Ask Photos,&quot; and examples of Ask Photos prompts.</description>
<source url="https://blog.google/technology/ai/rss/">google</source>
<category>ai</category>
<category>google</category>
<category>lab</category>
<category>nonpaper</category>
<category>photos</category>
<category>product</category>
<category>research</category>
</item>
<item>
<title>Helping kids and teens learn and grow online on Safer Internet Day</title>
<link>https://blog.google/innovation-and-ai/technology/safety-security/safer-internet-day-2026-kids-teens/</link>
<guid>title:helping kids and teens learn and grow online on safer internet day</guid>
<pubDate>Tue, 10 Feb 2026 02:30:00 +0000</pubDate>
<description>User profile on smartphone connected to security, media, and settings icons.</description>
<source url="https://blog.google/technology/ai/rss/">google</source>
<category>ai</category>
<category>google</category>
<category>lab</category>
<category>nonpaper</category>
<category>product</category>
<category>research</category>
<category>safety &amp; security</category>
</item>
<item>
<title>Automating Inference Optimizations with NVIDIA TensorRT LLM AutoDeploy</title>
<link>https://developer.nvidia.com/blog/automating-inference-optimizations-with-nvidia-tensorrt-llm-autodeploy/</link>
<guid>title:automating inference optimizations with nvidia tensorrt llm autodeploy</guid>
<pubDate>Mon, 09 Feb 2026 18:30:00 +0000</pubDate>
<description>NVIDIA TensorRT LLM enables developers to build high-performance inference engines for large language models (LLMs), but deploying a new architecture...</description>
<source url="https://developer.nvidia.com/blog/feed">nvidia</source>
<category>agentic ai / generative ai</category>
<category>ai inference</category>
<category>developer tools &amp; techniques</category>
<category>hardware</category>
<category>inference performance</category>
<category>infra</category>
<category>llm</category>
<category>llms</category>
<category>mlops</category>
<category>nonpaper</category>
<category>nvidia</category>
<category>pytorch</category>
<category>serving</category>
<category>training</category>
</item>
<item>
<title>How AI trained on birds is surfacing underwater mysteries</title>
<link>https://research.google/blog/how-ai-trained-on-birds-is-surfacing-underwater-mysteries/</link>
<guid>title:how ai trained on birds is surfacing underwater mysteries</guid>
<pubDate>Mon, 09 Feb 2026 18:38:00 +0000</pubDate>
<description>Climate &amp; Sustainability</description>
<source url="https://research.google/blog/rss/">google-research</source>
<category>climate &amp; sustainability</category>
<category>google-research</category>
<category>models</category>
<category>nonpaper</category>
<category>open source models &amp; datasets</category>
<category>research</category>
<category>science</category>
<category>sound &amp; accoustics</category>
</item>
<item>
<title>Anthropic AI safety researcher quits, says the ‚Äòworld is in peril‚Äô</title>
<link>https://globalnews.ca/news/11664538/anthropic-ai-safety-researcher-mrinank-sharma-quits-concerns/</link>
<guid>title:anthropic ai safety researcher quits says the world is in peril</guid>
<pubDate>Thu, 12 Feb 2026 17:00:46 +0000</pubDate>
<description>Anthropic was founded in 2021 by a breakaway group of former OpenAI employees who pledged to design a more safety-centric approach to AI development.</description>
<source url="https://globalnews.ca/tag/artificial-intelligence/feed">globalnews.ca</source>
<category>ai</category>
<category>artificial intelligence</category>
<category>globalnews.ca</category>
<category>news</category>
<category>nonpaper</category>
<category>rl</category>
<category>tech</category>
<category>trending</category>
<category>world</category>
</item>
<item>
<title>All you need to know about ü¶û OpenClaw</title>
<link>https://dev.to/xilinwei/all-you-need-to-know-about-openclaw-35cb</link>
<guid>title:all you need to know about openclaw</guid>
<pubDate>Sun, 22 Feb 2026 08:28:32 +0000</pubDate>
<description>All you need to know about ü¶û OpenClaw --- The Complete Guide to Your Personal AI Agent Everything you need to know about the open-source AI agent that went from zero to 140K GitHub stars in under three months. üìö Table of Contents Introduction &amp;amp; Context Architecture &amp;amp; High-Level Design Getting Started (Step-by-Step Guide) Practical Applications &amp;amp; Productivity Optimization, Security &amp;amp; Challenges 1. Introduction What is OpenClaw, Really? Imagine having an assistant that can actually do things ‚Äî not just answer questions or generate text, but execute tasks, manage your schedule, write code, control your smart home, and respond on your behalf ‚Äî all running privately on your own hardware, with zero data leaving your machine. That's OpenClaw. Formerly known as Clawdbot and then Moltbot, it's one of the fastest-growing open-source projects of early 2026.</description>
<source url="https://dev.to/feed">dev.to</source>
<category>agents</category>
<category>ai</category>
<category>dev.to</category>
<category>diffusion</category>
<category>llm</category>
<category>news</category>
<category>nonpaper</category>
<category>opensource</category>
<category>reasoning</category>
<category>rl</category>
<category>tutorial</category>
</item>
<item>
<title>Introducing WorldVQA √¢¬Ä¬ã</title>
<link>https://www.kimi.com/blog/worldvqa.html</link>
<guid>title:introducing worldvqa</guid>
<pubDate>Sun, 22 Feb 2026 08:44:49 +0000</pubDate>
<description>A benchmark for evaluating atomic visual world knowledge in Multimodal LLMs. Authors Kimi Team We are releasing WorldVQA , a new benchmark designed to measure the factual correctness of Multimodal Large Language Models (MLLMs). While recent models have demonstrated impressive capabilities in visual reasoning and description, measuring their reliability regarding visual world knowledge remains a challenge.</description>
<source url="https://www.kimi.com/blog">kimi</source>
<category>kimi</category>
<category>lab</category>
<category>llm</category>
<category>models</category>
<category>multimodal</category>
<category>nonpaper</category>
<category>product</category>
<category>reasoning</category>
<category>rl</category>
</item>
<item>
<title>How will we do SFT on models with opaque reasoning?</title>
<link>https://www.alignmentforum.org/posts/GJTzhQgaRWLFJkPbt/how-will-we-do-sft-on-models-with-opaque-reasoning</link>
<guid>title:how will we do sft on models with opaque reasoning</guid>
<pubDate>Sat, 21 Feb 2026 00:00:17 +0000</pubDate>
<description>Published on February 21, 2026 12:00 AM GMT Current LLMs externalize lots of their reasoning in human interpretable language. This reasoning is sometimes unfaithful , sometimes strange and concerning , and LLMs can do somewhat impressive reasoning without using CoT , but my overall impression is that CoT currently is a reasonably complete and accurate representation of LLM reasoning. However, reasoning in interpretable language might turn out to be uncompetitive‚Äîif so, it seems probable that opaque reasoning will be adopted in frontier AI labs. If future AI models have opaque reasoning, this will probably change what training we can apply to these AIs. For example, currently we train models to reason in a good way about math problems, or to reason in a desired way about the spec that we hope they‚Äôll follow. It‚Äôs not obvious that we‚Äôll be able to do training that affects model reasoning like this if models have opaque reasoning though, because we can‚Äôt just write the reasoning ourselves and do SFT on the reasoning trace.</description>
<source url="https://www.alignmentforum.org/feed.xml">alignment-forum</source>
<category>alignment</category>
<category>alignment-forum</category>
<category>diffusion</category>
<category>governance</category>
<category>llm</category>
<category>nonpaper</category>
<category>reasoning</category>
<category>rl</category>
<category>safety</category>
</item>
<item>
<title>Kimi K2.5: Visual Agentic Intelligence √¢¬Ä¬ã</title>
<link>https://www.kimi.com/blog/kimi-k2-5.html</link>
<guid>title:kimi k2 5 visual agentic intelligence</guid>
<pubDate>Sun, 22 Feb 2026 08:44:50 +0000</pubDate>
<description>Today, we are introducing Kimi K2. 5, the most powerful open-source model to date. Kimi K2. 5 builds on Kimi K2 with continued pretraining over approximately 15T mixed visual and text tokens. Built as a native multimodal model, K2. 5 delivers state-of-the-art coding and vision capabilities and a self-directed agent swarm paradigm.</description>
<source url="https://www.kimi.com/blog">kimi</source>
<category>agents</category>
<category>kimi</category>
<category>lab</category>
<category>models</category>
<category>multimodal</category>
<category>nonpaper</category>
<category>product</category>
<category>vision</category>
</item>
<item>
<title>Project Vend: Phase two</title>
<link>https://www.anthropic.com/research/project-vend-2</link>
<guid>title:project vend phase two</guid>
<pubDate>Sun, 22 Feb 2026 08:44:27 +0000</pubDate>
<description>In June, we revealed that we‚Äôd set up a small shop in our San Francisco office lunchroom, run by an AI shopkeeper. It was part of Project Vend , a free-form experiment exploring how well AIs could do on complex, real-world tasks. Alas, the shopkeeper‚Äîa modified version of Claude we named ‚ÄúClaudius‚Äù‚Äîdid not do particularly well. It lost money over time, had a strange identity crisis where it claimed it was a human wearing a blue blazer, and was goaded by mischievous Anthropic employees into selling products (particularly, for some reason, tungsten cubes) at a substantial loss. But the capabilities of large language models in areas like reasoning, writing, coding, and much else besides are increasing at a breathless pace. Has Claudius‚Äôs ‚Äúrunning a shop‚Äù capability shown the same improvement?</description>
<source url="https://www.anthropic.com/research">anthropic</source>
<category>anthropic</category>
<category>lab</category>
<category>llm</category>
<category>models</category>
<category>nonpaper</category>
<category>reasoning</category>
<category>research</category>
<category>rl</category>
</item>
<item>
<title>Hud.io Doesn‚Äôt Replace Observability It Replaces Guessing</title>
<link>https://dev.to/aws-builders/hudio-doesnt-replace-observability-it-replaces-guessing-13m2</link>
<guid>title:hud io doesn t replace observability it replaces guessing</guid>
<pubDate>Sun, 22 Feb 2026 08:25:10 +0000</pubDate>
<description>üëã Hey there, tech enthusiasts! I'm Sarvar, a Cloud Architect with a passion for transforming complex technological challenges into elegant solutions. With extensive experience spanning Cloud Operations (AWS &amp;amp; Azure), Data Operations, Analytics, DevOps, and Generative AI, I've had the privilege of architecting solutions for global enterprises that drive real business impact. Through this article series, I'm excited to share practical insights, best practices, and hands-on experiences from my journey in the tech world. Whether you're a seasoned professional or just starting out, I aim to break down complex concepts into digestible pieces that you can apply in your projects. Let's dive in and explore the fascinating world of cloud technology together!</description>
<source url="https://dev.to/feed">dev.to</source>
<category>agents</category>
<category>ai</category>
<category>aws</category>
<category>dev.to</category>
<category>hud</category>
<category>news</category>
<category>nonpaper</category>
<category>reasoning</category>
<category>rl</category>
<category>security</category>
</item>
<item>
<title>The Discipline of Not Fooling Ourselves: Episode 2 ‚Äî When Success Is Declared Too Early</title>
<link>https://dev.to/abdulosman/the-discipline-of-not-fooling-ourselves-episode-2-when-success-is-declared-too-early-2k6e</link>
<guid>title:the discipline of not fooling ourselves episode 2 when success is declared too early</guid>
<pubDate>Sun, 22 Feb 2026 08:16:00 +0000</pubDate>
<description>The Moment Effort Turns into Relief There is a moment in many organizations when sustained effort gives way to relief. A demanding phase ends: a review cycle, a release, an assessment, a milestone. The pressure lifts. Conversations soften. People breathe again. Language shifts subtly from ‚ÄúWhat are we missing?</description>
<source url="https://dev.to/feed">dev.to</source>
<category>ai</category>
<category>alignment</category>
<category>compliance</category>
<category>corporateculture</category>
<category>dev.to</category>
<category>discuss</category>
<category>news</category>
<category>nonpaper</category>
<category>process</category>
<category>rl</category>
<category>vision</category>
</item>
<item>
<title>A New Google AI Research Proposes Deep-Thinking Ratio to Improve LLM Accuracy While Cutting Total Inference Costs by Half</title>
<link>https://www.marktechpost.com/2026/02/21/a-new-google-ai-research-proposes-deep-thinking-ratio-to-improve-llm-accuracy-while-cutting-total-inference-costs-by-half/</link>
<guid>title:a new google ai research proposes deep thinking ratio to improve llm accuracy while cutting total inference costs by half</guid>
<pubDate>Sun, 22 Feb 2026 04:53:19 +0000</pubDate>
<description>For the last few years, the AI world has followed a simple rule: if you want a Large Language Model (LLM) to solve a harder problem, make its Chain-of-Thought (CoT) longer. But new research from the University of Virginia and Google proves that &amp;#8216;thinking long&amp;#8217; is not the same as &amp;#8216;thinking hard&amp;#8217;. The research team [&amp;#8230;] The post A New Google AI Research Proposes Deep-Thinking Ratio to Improve LLM Accuracy While Cutting Total Inference Costs by Half appeared first on MarkTechPost .</description>
<source url="https://www.marktechpost.com/feed">marktechpost.com</source>
<category>ai</category>
<category>ai infrastructure</category>
<category>ai paper summary</category>
<category>ai shorts</category>
<category>applications</category>
<category>artificial intelligence</category>
<category>editors pick</category>
<category>language model</category>
<category>llm</category>
<category>marktechpost.com</category>
<category>news</category>
<category>nonpaper</category>
<category>rl</category>
<category>serving</category>
<category>staff</category>
<category>tech news</category>
<category>technology</category>
<category>uncategorized</category>
</item>
<item>
<title>ggml.ai joins Hugging Face to ensure the long-term progress of Local AI</title>
<link>https://simonwillison.net/2026/Feb/20/ggmlai-joins-hugging-face/#atom-everything</link>
<guid>title:ggml ai joins hugging face to ensure the long term progress of local ai</guid>
<pubDate>Fri, 20 Feb 2026 17:12:55 +0000</pubDate>
<description>ggml. ai joins Hugging Face to ensure the long-term progress of Local AI I don't normally cover acquisition news like this, but I have some thoughts. It's hard to overstate the impact Georgi Gerganov has had on the local model space. Back in March 2023 his release of llama. cpp made it possible to run a local LLM on consumer hardware. The original README said: The main goal is to run the model using 4-bit quantization on a MacBook.</description>
<source url="https://simonwillison.net/atom/everything/">simonwillison</source>
<category>ai</category>
<category>diffusion</category>
<category>efficiency</category>
<category>engineering</category>
<category>generative-ai</category>
<category>hugging-face</category>
<category>llama</category>
<category>llama-cpp</category>
<category>llm</category>
<category>llms</category>
<category>local-llms</category>
<category>nonpaper</category>
<category>open-source</category>
<category>rl</category>
<category>serving</category>
<category>simonwillison</category>
<category>tools</category>
<category>transformers</category>
</item>
<item>
<title>Kimi Introduces Agent Swarm: Let 100 AI Agents Work for You √¢¬Ä¬ã</title>
<link>https://www.kimi.com/blog/agent-swarm.html</link>
<guid>title:kimi introduces agent swarm let 100 ai agents work for you</guid>
<pubDate>Sun, 22 Feb 2026 08:44:49 +0000</pubDate>
<description>In 2025, if you walked into any AI conference, you may hear the same gospel: faster inference, longer context windows, cheaper inference costs. It's as if we've spent years perfecting the hammer, making it lighter, stronger, more precisely balanced, while never questioning the fact that the carpenter still has only two hands and twenty-four hours in a day. Now, Kimi introduces Agent Swarm. It is not a better hammer. It is a reconstruction of the entire workshop.</description>
<source url="https://www.kimi.com/blog">kimi</source>
<category>agents</category>
<category>kimi</category>
<category>lab</category>
<category>models</category>
<category>nonpaper</category>
<category>product</category>
<category>serving</category>
</item>
<item>
<title>Signs of introspection in large language models</title>
<link>https://www.anthropic.com/research/introspection</link>
<guid>title:signs of introspection in large language models</guid>
<pubDate>Sun, 22 Feb 2026 08:44:28 +0000</pubDate>
<description>Have you ever asked an AI model what‚Äôs on its mind? Or to explain how it came up with its responses? Models will sometimes answer questions like these, but it‚Äôs hard to know what to make of their answers. Can AI systems really introspect‚Äîthat is, can they consider their own thoughts? Or do they just make up plausible-sounding answers when they‚Äôre asked to do so? Understanding whether AI systems can truly introspect has important implications for their transparency and reliability.</description>
<source url="https://www.anthropic.com/research">anthropic</source>
<category>anthropic</category>
<category>lab</category>
<category>llm</category>
<category>models</category>
<category>nonpaper</category>
<category>reasoning</category>
<category>research</category>
</item>
<item>
<title>Economic Research</title>
<link>https://www.anthropic.com/research/team/economic-research</link>
<guid>title:economic research</guid>
<pubDate>Sun, 22 Feb 2026 08:44:16 +0000</pubDate>
<description>The Economic Research team studies how AI is reshaping the economy, including work, productivity, and economic opportunity. Through rigorous data collection and analysis, we track AI's real-world economic effects and publish research that helps policymakers, businesses, and the public understand and prepare for the changes ahead. We build the empirical foundation for understanding AI's economic impact. Our flagship Anthropic Economic Index tracks how AI tools are actually being used around the world and across every sector of the economy‚Äîmoving beyond speculation to measure adoption patterns as they unfold. Alongside our index reports, we produce novel research that studies the implications of AI usage and diffusion‚Äîas tracked in the index‚Äîfor workers, for firms, and for the broader economy. Economic transitions create both opportunity and disruption.</description>
<source url="https://www.anthropic.com/research">anthropic</source>
<category>anthropic</category>
<category>diffusion</category>
<category>lab</category>
<category>models</category>
<category>nonpaper</category>
<category>research</category>
<category>rl</category>
</item>
<item>
<title>Alignment</title>
<link>https://www.anthropic.com/research/team/alignment</link>
<guid>title:alignment</guid>
<pubDate>Sun, 22 Feb 2026 08:44:12 +0000</pubDate>
<description>Future AI systems will be even more powerful than today‚Äôs, likely in ways that break key assumptions behind current safety techniques. That‚Äôs why it‚Äôs important to develop sophisticated safeguards to ensure models remain helpful, honest, and harmless. The Alignment team works to understand the challenges ahead and create protocols to train, evaluate, and monitor highly-capable models safely. Alignment researchers validate that models are harmless and honest even under very different circumstances than those under which they were trained. They also develop methods to allow humans to collaborate with language models to verify claims that humans might not be able to on their own. Alignment researchers also systematically look for situations in which models might behave badly, and check whether our existing safeguards are sufficient to deal with risks that human-level capabilities may bring.</description>
<source url="https://www.anthropic.com/research">anthropic</source>
<category>alignment</category>
<category>anthropic</category>
<category>lab</category>
<category>llm</category>
<category>models</category>
<category>nonpaper</category>
<category>research</category>
</item>
<item>
<title>Research</title>
<link>https://www.anthropic.com/research</link>
<guid>title:research</guid>
<pubDate>Sun, 22 Feb 2026 08:44:07 +0000</pubDate>
<description>Our research teams investigate the safety, inner workings, and societal impacts of AI models ‚Äì so that artificial intelligence has a positive impact as it becomes increasingly capable. The mission of the Interpretability team is to discover and understand how large language models work internally, as a foundation for AI safety and positive outcomes. The Alignment team works to understand the risks of AI models and develop ways to ensure that future ones remain helpful, honest, and harmless.</description>
<source url="https://www.anthropic.com/research">anthropic</source>
<category>alignment</category>
<category>anthropic</category>
<category>lab</category>
<category>llm</category>
<category>models</category>
<category>nonpaper</category>
<category>research</category>
</item>
<item>
<title>One OpenClaw Gateway Multiple Isolated AI Assistants (One Telegram Bot Per Worker)</title>
<link>https://dev.to/onin/one-openclaw-gateway-multiple-isolated-ai-assistants-one-telegram-bot-per-worker-3k97</link>
<guid>title:one openclaw gateway multiple isolated ai assistants one telegram bot per worker</guid>
<pubDate>Sun, 22 Feb 2026 08:30:06 +0000</pubDate>
<description>tldr; Give every team member their own private AI employee on a single machine. Full isolation, zero extra servers, Telegram-only setup in minutes. Abstract Tired of spinning up separate servers or cloud instances for every AI assistant in your company? OpenClaw lets you run dozens of completely separate, fully isolated agents on one single machine ‚Äî and Telegram makes the UX feel magical. Each worker gets their own dedicated bot ( @AliceSalesClawBot , @BobSupportClawBot , etc. ).</description>
<source url="https://dev.to/feed">dev.to</source>
<category>agents</category>
<category>ai</category>
<category>dev.to</category>
<category>llm</category>
<category>news</category>
<category>nonpaper</category>
<category>openclaw</category>
<category>telegram</category>
</item>
<item>
<title>Give LLMs a Shot</title>
<link>https://dev.to/theunsuredev/give-llms-a-shot-56f7</link>
<guid>title:give llms a shot</guid>
<pubDate>Sun, 22 Feb 2026 08:17:16 +0000</pubDate>
<description>&quot;Brevity is the soul of wit&quot; - William Shakespeare, Hamlet Originally published at: https://theunsuredeveloper. com/give-llms-a-shot &quot;I'm temporarily departing this establishment in order to acquire a more suitably reinforced transportation vehicle capable of facilitating my immediate objective of re-entry through your currently locked access point, at which time I will resume this interaction with considerably greater efficacy and substantially reduced regard for architectural barriers, so you may wish to interpret this announcement not as a polite farewell but as both a menacing and statistically reliable guarantee of my imminent and forceful return&quot; is what Arnold Schwarzenegger could have said to the desk sergeant, but thankfully he spared us the diatribe and left us with one of the most memorable quotes in movie history: T-800 - Terminator 2: Judgment Day Great one-liners tend to stick with us. They're short. They're sharp. They achieve a precise purpose. In software, I love one-liners!</description>
<source url="https://dev.to/feed">dev.to</source>
<category>ai</category>
<category>bash</category>
<category>dev.to</category>
<category>devops</category>
<category>llm</category>
<category>news</category>
<category>nonpaper</category>
<category>rl</category>
</item>
<item>
<title>Building a Cross-Chain Confidential &quot;Trust Score Oracle&quot; with Oasis Sapphire + OPL + ROFL</title>
<link>https://dev.to/rollingindo/building-a-cross-chain-confidential-trust-score-oracle-with-oasis-sapphire-opl-rofl-39n8</link>
<guid>title:building a cross chain confidential trust score oracle with oasis sapphire opl rofl</guid>
<pubDate>Sun, 22 Feb 2026 08:15:46 +0000</pubDate>
<description>This tutorial shows how to add privacy + verifiable off-chain compute to any EVM dApp by combining: Sapphire: Oasis‚Äô confidential EVM (encrypted calldata + confidential contract state). OPL (Oasis Privacy Layer): message bridge pattern to ‚Äúbolt privacy onto‚Äù existing EVM apps by offloading sensitive logic to Sapphire. ROFL (Runtime Off-Chain Logic): a TEE-managed app runtime (containers or single binaries) with secrets stored via built-in KMS and on-chain management through Sapphire. Real use case You run a lending/access-control dApp on a Home chain (Ethereum/L2). You want a wallet &quot;Trust Score&quot; derived from sensitive signals: private allowlists (KYC provider, internal risk flags), off-chain identity reputation (GitHub activity, paid subscription, enterprise customer), model inference results (fraud classifier). You don‚Äôt want to leak: raw signals, model features, user identity mappings, or scoring logic.</description>
<source url="https://dev.to/feed">dev.to</source>
<category>ai</category>
<category>blockchain</category>
<category>confidentiality</category>
<category>dev.to</category>
<category>news</category>
<category>nonpaper</category>
<category>privacy</category>
<category>rl</category>
<category>serving</category>
<category>web3</category>
</item>
<item>
<title>Anthropic's data shows software engineering accounts for ~50% of its AI agent tool calls; the remaining verticals are greenfields most founders are overlooking (Garry Tan/Garry's List)</title>
<link>http://www.techmeme.com/260222/p6#a260222p6</link>
<guid>title:anthropic s data shows software engineering accounts for 50 of its ai agent tool calls the remaining verticals are greenfields most founders are overlooking garry tan garry s list</guid>
<pubDate>Sun, 22 Feb 2026 07:00:02 +0000</pubDate>
<description>Garry Tan / Garry's List : Anthropic's data shows software engineering accounts for ~50% of its AI agent tool calls; the remaining verticals are greenfields most founders are overlooking &amp;nbsp; &amp;mdash;&amp;nbsp; Anthropic's new data shows software engineering dominates agentic AI.&amp;nbsp; For founders, that's not a warning.&amp;nbsp; It's a treasure map.</description>
<source url="https://www.techmeme.com/feed.xml">techmeme.com</source>
<category>agents</category>
<category>ai</category>
<category>news</category>
<category>nonpaper</category>
<category>rl</category>
<category>techmeme.com</category>
</item>
<item>
<title>Does Gemini 3.1 Pro Matter?</title>
<link>https://podcasters.spotify.com/pod/show/nlw/episodes/Does-Gemini-3-1-Pro-Matter-e3fcld4</link>
<guid>title:does gemini 3 1 pro matter</guid>
<pubDate>Fri, 20 Feb 2026 20:52:38 +0000</pubDate>
<description>Gemini 3. 1 Pro arrives with big benchmark gains and a sharp jump in reasoning, coding, and efficiency‚Äîbut in a world where the frontier rotates weekly, raw performance isn‚Äôt the story. This episode looks at what actually matters: cost per task, multimodal dominance, and where Gemini fits in a model portfolio that now demands specialization over supremacy. In the headlines: India‚Äôs AI Impact Summit and the Altman-Amodei moment, Walmart bets on AI for growth, Amazon tracks employee AI usage, and Accenture ties promotions to adoption. Want to build with OpenClaw? LEARN MORE ABOUT CLAW CAMP: ‚Å†‚Å†‚Å†‚Å†https://campclaw.</description>
<source url="https://feeds.libsyn.com/468519/rss">feeds.libsyn.com</source>
<category>agents</category>
<category>ai</category>
<category>feeds.libsyn.com</category>
<category>multimodal</category>
<category>news</category>
<category>nonpaper</category>
<category>reasoning</category>
<category>rl</category>
<category>robotics</category>
</item>
<item>
<title>Claude Code NEW Design Canvas With Built-In Figma That's FREE! (Pencil.dev)</title>
<link>https://www.youtube.com/watch?v=CBIUxXy3WmM</link>
<guid>title:claude code new design canvas with built in figma that s free pencil dev</guid>
<pubDate>Sun, 22 Feb 2026 06:42:57 +0000</pubDate>
<description>Say goodbye to generic AI designs! üòé In this video, we dive into Claude Code‚Äôs newest workflow combined with Pencil. dev, a fully free infinite design canvas that acts like Figma ‚Äî but better for AI-assisted frontend development. üîó My Links: Sponsor a Video or Do a Demo of Your Product, Contact me: intheworldzofai@gmail. com üî• Become a Patron (Private Discord): https://patreon. com/WorldofAi üß† Follow me on Twitter: https://twitter.</description>
<source url="https://www.youtube.com/feeds/videos.xml?channel_id=UC2WmuBuFq6gL08QYG-JjXKw">youtube.com</source>
<category>agents</category>
<category>ai</category>
<category>news</category>
<category>nonpaper</category>
<category>rl</category>
<category>youtube.com</category>
</item>
<item>
<title>Adding TILs, releases, museums, tools and research to my blog</title>
<link>https://simonwillison.net/2026/Feb/20/beats/#atom-everything</link>
<guid>title:adding tils releases museums tools and research to my blog</guid>
<pubDate>Fri, 20 Feb 2026 23:47:10 +0000</pubDate>
<description>I've been wanting to add indications of my various other online activities to my blog for a while now. I just turned on a new feature I'm calling &quot;beats&quot; (after story beats, naming this was hard! ) which adds five new types of content to my site, all corresponding to activity elsewhere. Here's what beats look like: Those three are from the 30th December 2025 archive page. Beats are little inline links with badges that fit into different content timeline views around my site, including the homepage, search and archive pages. There are currently five types of beats: Releases are GitHub releases of my many different open source projects, imported from this JSON file that was constructed by GitHub Actions .</description>
<source url="https://simonwillison.net/atom/everything/">simonwillison</source>
<category>agents</category>
<category>ai</category>
<category>ai-assisted-programming</category>
<category>blogging</category>
<category>claude-artifacts</category>
<category>claude-code</category>
<category>engineering</category>
<category>generative-ai</category>
<category>llm</category>
<category>llms</category>
<category>museums</category>
<category>nonpaper</category>
<category>serving</category>
<category>simonwillison</category>
<category>til</category>
<category>tools</category>
</item>
<item>
<title>Blog</title>
<link>https://cooperbench.com/blog</link>
<guid>title:blog</guid>
<pubDate>Sun, 22 Feb 2026 08:44:53 +0000</pubDate>
<description>Feburary 2026 We studied agents' miscoordination behavior, and it is more interesting than you imagined. Arpandeep Khatua, Hao Zhu</description>
<source url="https://cooperbench.com/">benchmarks</source>
<category>agents</category>
<category>benchmarks</category>
<category>evals</category>
<category>nonpaper</category>
</item>
</channel>
</rss>